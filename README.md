# ğŸ§  Member QA System

A **production-ready Natural Language Question Answering (QA)** system for querying **member data** using advanced **semantic search**, **retrieval-augmented LLM reasoning**, and **FastAPI**.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![LLM](https://img.shields.io/badge/LLM-Llama_3.2-orange.svg)](https://ollama.com)
[![Status](https://img.shields.io/badge/Status-Deployed-success.svg)](#live-demo)

---

## ğŸš€ Live Demo

> The system is **live and publicly accessible**.

| Resource | URL |
|-----------|------|
| ğŸŒ **Live API** | [comfortless-undefiant-aaron.ngrok-free.dev](https://comfortless-undefiant-aaron.ngrok-free.dev) |
| ğŸ“˜ **Interactive Docs** | [Swagger UI](https://comfortless-undefiant-aaron.ngrok-free.dev/docs) |
| ğŸ©º **Health Check** | [Check Status](https://comfortless-undefiant-aaron.ngrok-free.dev/health) |

### Quick Test (cURL)
```bash
curl -X POST "https://comfortless-undefiant-aaron.ngrok-free.dev/ask?use_cached_data=true"   -H "Content-Type: application/json"   -d '{"question": "When is Layla planning her trip to London?"}'
```

---

## ğŸ’¡ Example Questions

| Question | Example Answer |
|-----------|----------------|
| â€œWhen is Layla planning her trip to London?â€ | Layla is planning her trip to London starting Monday, March 11th, and staying at Claridgeâ€™s for five nights. |
| â€œWhat does Vikram need?â€ | Vikram needs a yoga instructor for their stay at the villa in Tuscany. |

### Example Response
```json
{
  "answer": "Layla is planning her trip to London starting Monday, March 11th, and staying at Claridge's for five nights.",
  "confidence": 0.35,
  "metadata": {
    "person_name": "Layla Kawaguchi",
    "messages_found": 330,
    "relevant_messages": 10,
    "retrieval_method": "semantic",
    "llm_model": "llama3.2:3b",
    "used_cached_data": true
  }
}
```

---

## âš™ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        User Question        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
     ğŸ” Extract Person Name
               â–¼
    ğŸ§  Semantic Message Search
               â–¼
   ğŸ—£ï¸  LLM Answer Generation
               â–¼
   âœ… JSON Answer + Confidence
```

**Key Components**
- **Person Extraction:** Identifies which of 10 known members the query is about.  
- **Retriever:** Performs semantic similarity search across ~3,349 messages.  
- **Generator:** Uses *Llama 3.2 (3B)* via **Ollama** for reasoning and answer synthesis.  
- **Cache:** `diskcache` for performance and persistence.  

---

## ğŸ§© API Endpoints

| Method | Endpoint | Description |
|--------|-----------|-------------|
| `POST` | `/ask` | Ask a question (uses cache by default) |
| `GET` | `/health` | Health and uptime check |
| `GET` | `/docs` | Interactive Swagger UI |
| `GET` | `/stats` | Returns dataset and performance stats |
| `GET` | `/users` | Lists all known members |
| `POST` | `/refresh-data` | Forces data reload from API |

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-------------|
| **Framework** | FastAPI 0.104+ |
| **Language** | Python 3.11 |
| **LLM** | Llama 3.2 (3B) via Ollama |
| **Embeddings** | SentenceTransformers *(all-MiniLM-L6-v2)* |
| **Retrieval** | Semantic Similarity Search |
| **Caching** | diskcache (1-hour TTL) |
| **Deployment** | Docker + ngrok Tunnel |

---

## ğŸ—‚ï¸ Project Structure

```
member-qa-system/
â”œâ”€â”€ app.py                   # Entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # FastAPI app setup
â”‚   â”œâ”€â”€ qa_engine.py         # Core QA pipeline orchestration
â”‚   â”œâ”€â”€ llm_generator.py     # Llama 3.2 integration
â”‚   â”œâ”€â”€ hybrid_retriever.py  # Semantic search & ranking
â”‚   â”œâ”€â”€ data_fetcher.py      # Cached data loader
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ messages_checkpoint.ndjson  # Dataset (3,349 messages)
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

---

## âš¡ Performance Overview

| Metric | Value |
|--------|--------|
| **Messages Loaded** | 3,349 |
| **Average Response Time** | 12â€“15 seconds |
| **Warm Cache Response** | <1 second |
| **Memory Usage** | ~500 MB |
| **Confidence Threshold** | 0.2 |

---

## ğŸ§® Data Management

- **Primary Source:** `messages_checkpoint.ndjson` (immutable dataset)
- **Cache Layer:** diskcache (with TTL = 1 hour)
- **Load Order:** Cache â†’ Local File â†’ External API (on force refresh)
- **Data Integrity:** No nulls, unique IDs, minor duplicates (2â€“3 max)

---

## ğŸ§  Design Notes

### Approaches Considered

| Approach | Verdict | Notes |
|-----------|----------|-------|
| Rule-Based Pattern Matching | âŒ Rejected | Rigid, fails with paraphrasing |
| BM25 Keyword Search | âŒ Rejected | Misses semantic intent |
| Hybrid (BM25 + Semantic) | âš ï¸ Evaluated | Slightly better, slower |
| **Pure Semantic Search** | âœ… Chosen | Best recall and flexibility |
| Gemma 3 QA | âŒ Rejected | Overly cautious, frequent refusals |
| **Llama 3.2 (3B)** | âœ… Deployed | Natural, contextual reasoning |

---

## ğŸ” Data Insights

| Observation | Description |
|--------------|-------------|
| **User Naming Variants** | Inconsistent formats per message thread |
| **Temporal Ambiguity** | Relative terms (e.g., â€œnext weekâ€) |
| **Pronoun Confusion** | Unclear referents (â€œsheâ€, â€œtheyâ€) |
| **Data Quality** | Clean â€” no nulls, minimal duplication |
| **Semantic Ambiguity** | â€œOwnsâ€ vs â€œlikesâ€ confusion in queries |
| **Event Overlap** | Multiple similar trips per user |

### User Distribution

| User | Message Count |
|------|----------------|
| Lily Oâ€™Sullivan | 365 |
| Thiago Monteiro | 361 |
| Fatima El-Tahir | 349 |
| Sophia Al-Farsi | 346 |
| Amina Van Den Berg | 342 |
| Vikram Desai | 335 |
| Layla Kawaguchi | 330 |
| Armand Dupont | 319 |
| Hans Miller | 314 |
| Lorenzo Cavalli | 288 |

---

## âœ… Requirements Checklist

| Category | Status |
|-----------|--------|
| Core QA Engine | âœ… Complete |
| REST Endpoints | âœ… Complete |
| JSON Schema | âœ… Complete |
| Semantic Retrieval | âœ… Complete |
| Public Deployment | âœ… Complete |
| Error Handling | âœ… Complete |
| Bonus: Design Notes | âœ… Complete |
| Bonus: Data Insights | âœ… Complete |

---

## ğŸ§° Setup & Installation

### Prerequisites
- Python â‰¥ 3.11  
- [Ollama](https://ollama.com) with **Llama 3.2**  
- Docker (optional, for containerized deployment)

### Local Setup

```bash
# 1. Pull Llama 3.2
ollama pull llama3.2:3b
ollama serve

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run the server
python app.py
```

Visit â†’ [http://localhost:8000](http://localhost:8000)

### Using Docker
```bash
docker-compose up
```

---

## ğŸ§­ Configuration

Environment variables are stored in `.env` or `src/config.py`:

| Key | Example |
|-----|----------|
| `LLM_MODEL` | `llama3.2:3b` |
| `RETRIEVAL_METHOD` | `semantic` |
| `SEMANTIC_THRESHOLD` | `0.2` |
| `API_BASE_URL` | `https://november7-730026606190.europe-west1.run.app` |

---

